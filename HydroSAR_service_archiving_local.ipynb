{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "<div><img src=\"https://radar.community.uaf.edu/wp-content/uploads/sites/667/2021/03/HydroSARbanner.jpg\" width=\"100%\" /></div>\n",
    "\n",
    "**NASA A.37 Project:** Integrating SAR Data for Improved Resilience and Response to Weather-Related Disasters\n",
    "**PI:** Franz J. Meyer\n",
    "\n",
    "# HydroSAR Transition workshop\n",
    "\n",
    "## Archiving successful HyP3 jobs in an AWS S3 bucket\n",
    "\n",
    "In order to automatically archive newly created HydroSAR products we:\n",
    "1. Query HyP3 for all the successful HydroSAR jobs we've submitted\n",
    "2. Query our archive for all the products we've archived\n",
    "3. Deduplicate the products lists to determine the *new* products to archive\n",
    "4. Transfer the new products to our archive\n",
    "\n",
    "This notebook walks through the archiving process and would be run on a regular schedule (cron) in application.\n",
    "\n",
    "Note: Here we're taking the strategy to *always* search for **all** possible products, *always* look up **all** previously created products, and then *deduplicate* the two lists to determine the new products. You could instead keep track of the last time the script was *successfully* run and only search for new products since then. While this would be more performant, our strategy is independent of previous runs so is generally more fault-tolerant and can be started and stopped at will."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Query HyP3 for all the HydroSAR products\n",
    "\n",
    "We use HyP3 as our workflow engine and can query for all the scenes we've already processed. Importantly, when we submit jobs, we will assign all of them a project name which is used to group jobs together and later search for them.\n",
    "\n",
    "First we need to specify our project name so that we can find all the jobs associated with the Area of Interest (AOI) we're monitoring"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "project_name = 'HKHwatermaps'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this notebook, we'll prompt for an Earthdata Login username and password, but they can be provided via the `username` and `password` keyword arguments, or automatically pulled from the users `~/.netrc` file.\n",
    "\n",
    "Note: Typically you'll want to use a shared \"operational\" Earthdata Login user as you can only search for jobs associated with your username."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import hyp3_sdk as sdk\n",
    "hyp3 = sdk.HyP3('https://hyp3-watermap.asf.alaska.edu', prompt=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we'll search for all the jobs with our project name and filter to the succeeded jobs."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "processed_jobs = hyp3.find_jobs(name=project_name)\n",
    "succeeded_jobs = processed_jobs.filter_jobs(running=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. Query our archive for all the products we've archived\n",
    "\n",
    "For our demonstration archive, we will store all the products in a directory on the local file system -- adjust for your archive accordingly."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "archive_directory = Path.cwd() / project_name\n",
    "archive_directory.mkdir(exist_ok=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We'll build our set of archived products by listing all the files in the directory."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "project_archive = {product.name for product in archive_directory.rglob('*.tif')}\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Importantly, this list will be a set of absolute file paths. For example, one item in the set looks like:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(next(iter(project_archive)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 3. Deduplicate the products lists and download *new* products to archive\n",
    "\n",
    "Every successful HyP3 `WATER_MAP` job will have created a set of HydroSAR products, each of which can be identified by its file suffix. First, we define the list products we'd like to archive:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "product_suffixes = ['_VV.tif', '_VH.tif', '_dem.tif', '_rgb.tif', '_WM_HAND.tif', '_WM.tif', '_FM_iterative_WaterDepth.tif', '_FM_iterative_FloodDepth.tif', '_FM_iterative_PW.tif']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Then we'll loop through all the succeeded jobs, see if all the products we want to archive are in the project archive, and if not download them into the archive."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from hyp3_sdk.util import download_file\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "jobs_to_archive = sdk.Batch()\n",
    "for job in tqdm(succeeded_jobs):\n",
    "    hyp3_product_name = job.files[0]['filename']\n",
    "    hyp3_product_url = job.files[0]['url']\n",
    "    for sfx in product_suffixes:\n",
    "        tif_name = hyp3_product_name.replace('.zip', sfx)\n",
    "        if tif_name not in project_archive:\n",
    "            download_file(hyp3_product_url.replace('.zip', sfx), archive_directory / tif_name, chunk_size=10485760)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here we are taking advantage of the fact the HyP3 uploads both the zip product package and the zip contents next to each other in the HyP3 AWS S3 content bucket. So you can get to a particular GeoTIFF by simply replacing the `.zip` in the download URL with the GeoTIFF's suffix."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}