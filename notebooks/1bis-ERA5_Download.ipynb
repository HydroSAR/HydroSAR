{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65b6fd1b-9647-4094-8383-74a88016aa3d",
   "metadata": {},
   "source": [
    "**This code will grab the extents of the RTCs you downloaded in the previous folder, as well as the temporal boundaries of your dataset. It will download Total Precipitations from ERA5 for the desired area. BE AWARE: depending on EMCWF's current requests number, this can take from several minutes to several hours**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8042eeab-84f9-48c1-b4f2-e8a6ef5f55c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cdsapi\n",
    "import xarray as xr\n",
    "import datetime\n",
    "from ipyfilechooser import FileChooser\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "import fierpy\n",
    "import glob\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from ipyfilechooser import FileChooser\n",
    "import re\n",
    "from fier_local import reof as freof\n",
    "from fier_local import sel_best_fit\n",
    "\n",
    "import opensarlab_lib as asfn\n",
    "from osgeo import gdal, osr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7609db07-38fc-4882-9c6c-e4f9c1e83497",
   "metadata": {},
   "source": [
    "**Function to grab the dates of the RTCs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8a0c197-ca89-452e-b444-99d6d884bd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates(dir_path, prefix):\n",
    "    dates = []\n",
    "    pths = list(dir_path.glob(f'{prefix}.tif*'))\n",
    "\n",
    "    for p in pths:\n",
    "        date_regex = '\\d{8}'\n",
    "        date = re.search(date_regex, str(p))\n",
    "        if date:\n",
    "            dates.append(date.group(0))\n",
    "    return dates\n",
    "\n",
    "\n",
    "               \n",
    "def get_coordinates_from_geotiff_bbox(geotiff_path):\n",
    "    dataset = gdal.Open(geotiff_path)\n",
    "\n",
    "    # Get the GeoTransform to convert pixel coordinates to geographical coordinates\n",
    "    transform = dataset.GetGeoTransform()\n",
    "\n",
    "    # Get the raster size (number of rows and columns)\n",
    "    cols = dataset.RasterXSize\n",
    "    rows = dataset.RasterYSize\n",
    "\n",
    "    # Get the four corner points in pixel coordinates\n",
    "    corners = [(0, 0), (cols, 0), (cols, rows), (0, rows)]\n",
    "\n",
    "    # Calculate the longitude (X) and latitude (Y) of each corner\n",
    "    corner_coordinates = []\n",
    "    for corner in corners:\n",
    "        lon = transform[0] + corner[0] * transform[1] + corner[1] * transform[2]\n",
    "        lat = transform[3] + corner[0] * transform[4] + corner[1] * transform[5]\n",
    "\n",
    "        # Get the spatial reference system of the dataset\n",
    "        srs = osr.SpatialReference()\n",
    "        srs.ImportFromWkt(dataset.GetProjection())\n",
    "\n",
    "        # Create a coordinate transformation object\n",
    "        target_srs = osr.SpatialReference()\n",
    "        target_srs.ImportFromEPSG(4326)  # EPSG code for WGS84\n",
    "        transform_obj = osr.CoordinateTransformation(srs, target_srs)\n",
    "\n",
    "        # Transform the coordinates to WGS84 (latitude and longitude)\n",
    "        lon, lat, _ = transform_obj.TransformPoint(lon, lat)\n",
    "\n",
    "        corner_coordinates.append((lat, lon))\n",
    "        \n",
    "    corner_coordinates = np.array(corner_coordinates)\n",
    "    boundaries = np.array([[np.min(corner_coordinates[:,1]), np.min(corner_coordinates[:,0])],\n",
    "                           [np.max(corner_coordinates[:,1]), np.max(corner_coordinates[:,0])]])\n",
    "\n",
    "    return boundaries\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e691a8b8-5872-4d4c-a2f1-725d8772c973",
   "metadata": {},
   "source": [
    "#### **Select the parent folder cointing your RTCs' folder**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b21eaa5-82df-4ddf-85e3-bfd5a5a6ac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = FileChooser(Path.cwd())\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae42f73-f1d5-4d61-9a0d-64b08f58daf3",
   "metadata": {},
   "source": [
    "**Grab the spatial and temporal extents of the tiffs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43dcee3-e875-4be0-a08e-7c2b0be8260e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the paths to the tiff files\n",
    "main_dir = Path(str(fc.selected))\n",
    "tiff_dir = list(main_dir.glob('*tiffs'))[0]\n",
    "tiffs = glob.glob(f\"{str(tiff_dir)}/*tif\")\n",
    "\n",
    "\n",
    "# Get the coordinates of the AOI\n",
    "geotiff_path = str(tiffs[0])\n",
    "boundaries = get_coordinates_from_geotiff_bbox(geotiff_path)\n",
    "for idx, corner in enumerate(boundaries, 1):\n",
    "    lat, lon = corner\n",
    "    print(f\"Corner {idx}: Latitude: {lat}, Longitude: {lon}\")\n",
    "\n",
    "times = get_dates(tiff_dir, '*VV')\n",
    "times.sort()\n",
    "times = pd.DatetimeIndex(times)\n",
    "times.name = \"time\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25292a96-13ce-45ef-83bb-be7bf71e98e3",
   "metadata": {},
   "source": [
    "**Send a quiery to EMCWF to grab the ERA5 precipitation data for the spatial and temporal extent of our tiffs.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6751cd33-5b48-461f-b847-9558cd900a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a folder to host the ERA5 data\n",
    "weather_data_folder = Path(fc.selected)/'ERA5'\n",
    "weather_data_folder.mkdir(exist_ok=True)\n",
    "\n",
    "\n",
    "# Create a new instance of the CDS API client\n",
    "# Define the API URL and key\n",
    "api_url = 'https://cds.climate.copernicus.eu/api/v2'\n",
    "api_key = '105035:a341bca0-1659-4056-a656-f4d505fffd4c'\n",
    "\n",
    "\n",
    "# Create the API client\n",
    "c = cdsapi.Client(url=api_url, key=api_key)\n",
    "\n",
    "# Create a list of the years covered by the tiffs\n",
    "years = [str(i) for i in np.arange(times.min().year, times.max().year+1)]\n",
    "\n",
    "# Get the data from ECMWF\n",
    "c.retrieve(\n",
    "        'reanalysis-era5-single-levels',\n",
    "        {\n",
    "            'product_type': 'reanalysis',\n",
    "            'variable': 'total_precipitation',\n",
    "            'format': 'netcdf',\n",
    "            'year': years,\n",
    "            'month': [\n",
    "                '01', '02', '03',\n",
    "                '04', '05', '06',\n",
    "                '07', '08', '09',\n",
    "                '10', '11', '12',\n",
    "            ],\n",
    "            'day': [\n",
    "                '01', '02', '03',\n",
    "                '04', '05', '06',\n",
    "                '07', '08', '09',\n",
    "                '10', '11', '12',\n",
    "                '13', '14', '15',\n",
    "                '16', '17', '18',\n",
    "                '19', '20', '21',\n",
    "                '22', '23', '24',\n",
    "                '25', '26', '27',\n",
    "                '28', '29', '30',\n",
    "                '31',\n",
    "            ],\n",
    "            'time': [\n",
    "                '00:00', '01:00', '02:00',\n",
    "                '03:00', '04:00', '05:00',\n",
    "                '06:00', '07:00', '08:00',\n",
    "                '09:00', '10:00', '11:00',\n",
    "                '12:00', '13:00', '14:00',\n",
    "                '15:00', '16:00', '17:00',\n",
    "                '18:00', '19:00', '20:00',\n",
    "                '21:00', '22:00', '23:00',\n",
    "            ],\n",
    "            'area': [boundaries[0,0], boundaries[0,1], boundaries[1,0], boundaries[1,1]],  # AOI\n",
    "        },\n",
    "        f'{weather_data_folder}/era5_data.nc',\n",
    ")\n",
    "\n",
    "# Load precipitation dataset's name\n",
    "filename = f'{weather_data_folder}/era5_data.nc'\n",
    "\n",
    "# Load it, drop the 2nd level of precipitation (expver=5), resample for 1 value per day, in-between are summed, and save as a netcdf\n",
    "ds = xr.open_dataset(filename).resample(time='D').sum().to_netcdf(f'{weather_data_folder}/era5_data.nc')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydrosar [conda env:.local-hydrosar]",
   "language": "python",
   "name": "conda-env-.local-hydrosar-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
