{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "098c263f-520d-4fc4-b0d3-0ea03991b5b3",
   "metadata": {},
   "source": [
    "<img src=\"https://radar.community.uaf.edu/wp-content/uploads/sites/667/2021/03/HydroSARbanner.jpg\" width=\"100%\" />\n",
    "\n",
    "<br>\n",
    "<font size=\"6\"> <b>FIER Daily Flood Forecasting Code</b><img style=\"padding: 7px\" src=\"https://radar.community.uaf.edu/wp-content/uploads/sites/667/2021/03/UAFLogo_A_647.png\" width=\"170\" align=\"right\"/></font>\n",
    "\n",
    "<br>\n",
    "<font size=\"4\"> <b> Franz J Meyer, University of Alaska Fairbanks</b> <br>\n",
    "</font>\n",
    "\n",
    "This notebooks is developing an algorithm to generate daily flood inundation predictions using time series of Sentinel-1 RTC data and GEOGLoWs river runoff forecasts. \n",
    "    \n",
    "The workflow utilizes information available in the fierpy <a href=\"https://github.com/SERVIR/fierpy\">fierpy</a> GitHub repository.\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50250be6-daef-416c-b9fb-770982ed6457",
   "metadata": {},
   "source": [
    "# Load Python Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06072e98-89d8-45b9-9911-b85403ac676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipyfilechooser import FileChooser\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "import fierpy\n",
    "import glob\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from ipyfilechooser import FileChooser\n",
    "import re\n",
    "from fier_local import reof as freof\n",
    "from fier_local import sel_best_fit\n",
    "import opensarlab_lib as asfn\n",
    "from osgeo import gdal, osr\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.dates as mdates\n",
    "import ipywidgets as widgets\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import KFold\n",
    "import sklearn.metrics as metrics\n",
    "import warnings\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3ae750-ab1c-4cbd-8f54-f27946b12889",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dates(dir_path, prefix):\n",
    "    dates = []\n",
    "    pths = list(dir_path.glob(f'{prefix}.tif*'))\n",
    "\n",
    "    for p in pths:\n",
    "        date_regex = '\\d{8}'\n",
    "        date = re.search(date_regex, str(p))\n",
    "        if date:\n",
    "            dates.append(date.group(0))\n",
    "    return dates\n",
    "\n",
    "# Normalize the datasets\n",
    "# Define the normalization function\n",
    "def normalize(arr):\n",
    "    # Calculate the maximum value in the slice\n",
    "    max_val = np.max(arr)\n",
    "    min_val = np.min(arr)\n",
    "    # Normalize the slice by dividing each element by the maximum value\n",
    "    normalized_arr = (arr - min_val)/(max_val - min_val)\n",
    "    return normalized_arr\n",
    "\n",
    "\n",
    "def append_all(dic, name, to_append):\n",
    "        for key1, nested_level1 in dic.items():\n",
    "            for key2, nested_level2 in nested_level1.items():\n",
    "                nested_level2[f'{name}'].append(to_append)  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4364c901-838b-4faf-885d-15b30ee8215f",
   "metadata": {},
   "source": [
    "**Function to grab the centerpoint coordinates of the AOI**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aaac9bc-dbf8-418d-b758-814cab292123",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_centerpoint_coordinates(tif_file):\n",
    "    dataset = gdal.Open(str(tif_file))\n",
    "    \n",
    "    # Get the geospatial transform\n",
    "    geotransform = dataset.GetGeoTransform()\n",
    "    \n",
    "    # Get the image size\n",
    "    width = dataset.RasterXSize\n",
    "    height = dataset.RasterYSize\n",
    "    \n",
    "    # Calculate the center pixel coordinates\n",
    "    center_x = geotransform[0] + (geotransform[1] * width + geotransform[2]) / 2\n",
    "    center_y = geotransform[3] + (geotransform[4] * height + geotransform[5]) / 2\n",
    "    \n",
    "    # Create a spatial reference object for EPSG:4326\n",
    "    src_srs = osr.SpatialReference()\n",
    "    src_srs.ImportFromEPSG(4326)\n",
    "    \n",
    "    # Create a spatial reference object for the TIF file\n",
    "    dataset_srs = osr.SpatialReference()\n",
    "    dataset_srs.ImportFromWkt(dataset.GetProjection())\n",
    "    \n",
    "    # Create a coordinate transformation object\n",
    "    coord_transform = osr.CoordinateTransformation(dataset_srs, src_srs)\n",
    "    \n",
    "    # Transform the center point coordinates to EPSG:4326\n",
    "    lon, lat, _ = coord_transform.TransformPoint(center_x, center_y)\n",
    "    \n",
    "    return lat, lon\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb8881a-cda4-47ad-ac7d-d6bfc1cf07a5",
   "metadata": {},
   "source": [
    "**Function to calculate the fits between data, discharge and precipitations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da99bc9-24ff-4ca9-b01d-b2a28083093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_fit_nn(var, reof_ds, dataset, models_neural):\n",
    "    # Get rid of the annoying warning that we should use datasets for optimized keras operations\n",
    "    tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "    \n",
    "    # Redirect standard output to a null device\n",
    "    sys.stdout = open(os.devnull, \"w\")\n",
    "\n",
    "\n",
    "    # Create a list that will host the best models\n",
    "    models = []\n",
    "\n",
    "    # Define the neural network architecture\n",
    "    def create_model():\n",
    "        model = keras.Sequential([\n",
    "            keras.layers.Dense(64, activation='relu', input_shape=(1,)),\n",
    "            keras.layers.Dense(64, activation='relu'),\n",
    "            keras.layers.Dense(1)\n",
    "        ])\n",
    "        model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "        return model\n",
    "\n",
    "    # Create a dictionnary to store statistics of each loop\n",
    "    fit_dict = dict()\n",
    "    dict_keys = ['fit_r2','pred_r','pred_rmse']\n",
    "\n",
    "    # Generate sample data\n",
    "    hindcast_var = (var-var.min())/(var.max()-var.min())\n",
    "    \n",
    "    # Reconstructed dataset \n",
    "    recon_da = np.zeros((dataset.shape))\n",
    "\n",
    "    # Loop through temporal modes to determine the regression between them and variable\n",
    "    for mode in reof_ds.mode.values:\n",
    "\n",
    "        hindcast_rtcp = (\n",
    "            reof_ds.temporal_modes[:,mode-1] - reof_ds.temporal_modes[:,mode-1].min())/(reof_ds.temporal_modes[:,mode-1].max() - reof_ds.temporal_modes[:,mode-1].min())\n",
    "\n",
    "        # Set up K-fold cross-validation\n",
    "        k = 3\n",
    "        kf = KFold(n_splits=k)\n",
    "\n",
    "        # Perform K-fold cross-validation and evaluate the models\n",
    "        best_model = None\n",
    "        best_score = np.inf\n",
    "\n",
    "        for train_index, val_index in kf.split(hindcast_var):\n",
    "            X_train, X_test = hindcast_var[train_index], hindcast_var[val_index]\n",
    "            y_train, y_test = hindcast_rtcp[train_index], hindcast_rtcp[val_index]\n",
    "\n",
    "            model = create_model()\n",
    "            model.fit(X_train, y_train, epochs=10, batch_size=32, verbose=0)\n",
    "            y_test_pred = model.predict(X_test)\n",
    "\n",
    "            rmse = metrics.mean_squared_error(y_test, y_test_pred,squared=False)\n",
    "\n",
    "            if rmse < best_score:\n",
    "                best_score = rmse\n",
    "                best_model = model\n",
    "\n",
    "        # Train the best model on the entire dataset\n",
    "        best_model.fit(hindcast_var, hindcast_rtcp, epochs=10, batch_size=32, verbose = 0)\n",
    "        \n",
    "        # Append the model in the list\n",
    "        models.append(best_model)\n",
    "\n",
    "        # Make predictions using the best model\n",
    "        hindcast_rtcp_pred = best_model.predict(hindcast_var)\n",
    "\n",
    "        # Convert to dataarray\n",
    "        hindcast_rtcp_pred_dataarray = var.copy()\n",
    "        hindcast_rtcp_pred_dataarray.values = hindcast_rtcp_pred[:, 0]\n",
    "\n",
    "        # Add to the reconstructed dataset\n",
    "        recon_da += hindcast_rtcp_pred_dataarray * reof_ds.spatial_modes[:,:,mode-1]\n",
    "\n",
    "    # Calculate distance between dataset and modeled dataset\n",
    "    rmse_dataset = np.sqrt(np.mean((normalize(recon_da) - normalize(dataset)) ** 2)).values\n",
    "    \n",
    "    # Restore standard output\n",
    "    sys.stdout = sys.__stdout__\n",
    "\n",
    "    return rmse_dataset, models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8596180d-5a0a-40ba-9efa-d0492132b11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synthesize_neural(var, model, reof_ds, dataset):\n",
    "    \n",
    "    # Make a copy of the template dataset\n",
    "    da_slice = dataset.copy()\n",
    "    # Reconstructed dataset \n",
    "    da_slice.values = np.zeros((var.time.shape[0], reof_ds.dims['lat'], reof_ds.dims['lon']))\n",
    "    \n",
    "    # Loop over the modes\n",
    "    for m in range(4):\n",
    "        \n",
    "        # Make predictions using the best model\n",
    "        forecast_rtcp = model[m].predict(var.values)\n",
    "        \n",
    "        # Convert to dataarray\n",
    "        forecast_rtcp_dataarray = var.copy()\n",
    "        forecast_rtcp_dataarray.values = forecast_rtcp[:, 0]\n",
    "\n",
    "        # Add to the reconstructed dataset\n",
    "        da_slice.values += forecast_rtcp_dataarray * reof_ds.spatial_modes[:,:,m]\n",
    "        \n",
    "        \n",
    "    return da_slice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068b4462-8199-452d-b7ec-4ff0f4cb70a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def looper(mm, type_file, pola, start_ind, metricranking, vv, fitting):\n",
    "    \n",
    "    \n",
    "    if type_file == 'SAR':\n",
    "        folder = 'RTC_GAMMA/'\n",
    "        if pola == 'VH and VV':\n",
    "            prefix = '*'\n",
    "        else:\n",
    "            prefix = f'*{pola}'\n",
    "    else:\n",
    "        folder = 'Water_Masks/'\n",
    "        if pola == 'VH and VV':\n",
    "            prefix = '*combined'\n",
    "        else:\n",
    "            prefix = f'*{pola}*'\n",
    "\n",
    "    tiff_dir = Path(fc.selected)/folder\n",
    "    tiffs = list(tiff_dir.glob(f'{prefix}.tif*'))\n",
    "    \n",
    "    times = get_dates(tiff_dir, prefix)\n",
    "    times.sort()\n",
    "    times = pd.DatetimeIndex(times)\n",
    "    times.name = \"time\"\n",
    "    \n",
    "    da = xr.concat([rxr.open_rasterio(f) for f in tiffs], dim=times)\n",
    "\n",
    "    # delete the extra data variable 'band'\n",
    "    da = da.sel(band=1, drop=True)\n",
    "    # rename autogenerated x,y as lon,lat \n",
    "    da = da.rename({'x': 'lon', 'y': 'lat'}).fillna(0)\n",
    "    \n",
    "    # Calculate the REOF of the dataset\n",
    "    reof_ds = (freof(da[:start_ind], n_modes = 4)).fillna(0)\n",
    "        \n",
    "    if fitting == True:    \n",
    "        # Calculate the fits\n",
    "        for var in ['Q','ERA']:\n",
    "\n",
    "            #### ---- Polynomial ---- ####\n",
    "            # Calculate the fits of different polynomials concerning each main mode\n",
    "            fits = fierpy.find_fits(reof_ds,mm[var]['Selected'],da[:start_ind])\n",
    "            # Grab the best fitting mode and coefficients\n",
    "            name,mode,coeffs = sel_best_fit(fits, metricranking[0], metricranking[1])\n",
    "\n",
    "            if metricranking[0] == 'r2':\n",
    "                suffix = 'fit'\n",
    "            else:\n",
    "                suffix = 'pred'\n",
    "\n",
    "            # Put score of this coeff in the score list\n",
    "            vv[var]['Polynomial']['Score'].append(fits[f\"{'_'.join(name.split('_')[:2])}_{suffix}_{metricranking[0]}\"])\n",
    "            vv[var]['Polynomial']['Coeffs'].append(coeffs)\n",
    "            vv[var]['Polynomial']['Modes'].append(mode)   \n",
    "\n",
    "\n",
    "            #### ---- Neural Network Regression ---- ####\n",
    "\n",
    "            rmse, models = find_best_fit_nn(mm[var]['Selected'], reof_ds, da[:start_ind], vv[var]['Neural']['Models'])\n",
    "            vv[var]['Neural']['RMSE'].append(rmse)\n",
    "            vv[var]['Neural']['Models'].append(models)\n",
    "    \n",
    "    \n",
    "    return reof_ds, da, vv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad71c05e-2b63-4fed-bd89-e7f7f3282502",
   "metadata": {},
   "source": [
    "**Function to create z-score flood maps from forecast and RTCs, and calculate their correspondance according to DeVries (2020)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e04bd98-956a-40d4-964c-c73bf834d6a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def z_score(dataset, variable, forecast_slice, hindcast_slice, nb_dry):\n",
    "\n",
    "    # Create dataframe\n",
    "    df = pd.DataFrame({'time': times[:start_ind], 'var': variable})\n",
    "\n",
    "    # Extract the year and month from the time column\n",
    "    df['year'] = df['time'].dt.year\n",
    "    df['month'] = df['time'].dt.month\n",
    "\n",
    "    # Group the DataFrame by year and month to calculate the monthly q_sel average\n",
    "    monthly_avg = df.groupby(['year', 'month'])['var'].mean().reset_index()\n",
    "\n",
    "    # Group the DataFrame by year and count the number of unique months\n",
    "    month_counts = monthly_avg.groupby('year')['month'].nunique()\n",
    "\n",
    "    # Get the years with at least nb_dry unique months\n",
    "    valid_years = month_counts[month_counts >= nb_dry].index\n",
    "\n",
    "    # Filter the DataFrame to include only the valid years\n",
    "    filtered_df = df[df['year'].isin(valid_years)]\n",
    "\n",
    "    # Group the filtered DataFrame by year and month to calculate the final monthly q_sel average\n",
    "    monthly_avg_filtered = filtered_df.groupby(['year', 'month'])['var'].mean().reset_index()\n",
    "\n",
    "    # Get the four months with the lowest average q_sel for each year\n",
    "    top_months = monthly_avg_filtered.groupby('year')['var'].nsmallest(nb_dry).index.get_level_values(1)\n",
    "\n",
    "    # Filter the DataFrame again to include only the top months\n",
    "    filtered_df = filtered_df[filtered_df['month'].isin(top_months)]\n",
    "\n",
    "    # Calculate the average and std of the baseline images of da that fall in the dry season indices\n",
    "    # We convert to dB follow DeVries (2020)\n",
    "    dataset2 = 10*np.log(dataset.where(dataset!=0, 1))\n",
    "    average = dataset2.isel(time=filtered_df.index).mean()\n",
    "    standard_deviation = dataset2.isel(time=filtered_df.index).std()\n",
    "\n",
    "    # Calculate the z_score\n",
    "    z_score_forecast = (10*np.log(forecast_slice) - average) /  standard_deviation\n",
    "    z_score_hindcast = (10*np.log(hindcast_slice) - average) /  standard_deviation\n",
    "\n",
    "    # Create flood matrices, where 0 is no flood and 1 is flood. Threshold is at -3 for flood pixels, following DeVries (2020)\n",
    "    flood_forecast = np.zeros((forecast_slice.shape))\n",
    "    flood_hindcast = np.zeros((hindcast_slice.shape))\n",
    "    flood_forecast[z_score_forecast < -3] = 1\n",
    "    flood_hindcast[z_score_hindcast < -3] = 1\n",
    "\n",
    "    # Calculate the indices for scoring: a = true positive, b = false positive, c = false negative, d = true negative\n",
    "    a = np.sum(np.logical_and(flood_forecast == 1, flood_hindcast == 1))\n",
    "    b = np.sum(np.logical_and(flood_forecast == 1, flood_hindcast == 0))\n",
    "    c = np.sum(np.logical_and(flood_forecast == 0, flood_hindcast == 1))\n",
    "    d = np.sum(np.logical_and(flood_forecast == 0, flood_hindcast == 0))\n",
    "\n",
    "    # Calculate the skills\n",
    "    overall_accuracy = ((a + b) / (a + b + c + d)) * 100\n",
    "    CSI = (a / (a + b + c)) * 100\n",
    "\n",
    "    return overall_accuracy, CSI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "453c7b89-dd45-49df-9aec-c7c099163d8d",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c25821-df72-4bb9-b032-fa04a942cffc",
   "metadata": {},
   "source": [
    "# Choose the folder of the area you want to work with (subfolder of \"Dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622cc161-c42b-4562-a34c-a14e867a3c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = FileChooser(Path.cwd())\n",
    "display(fc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dae8c8-a99b-4a28-9c12-ec60ead98506",
   "metadata": {},
   "source": [
    "#### **Instructions**\n",
    "\n",
    "**1 - Generate the flood percentage figure**  \n",
    "\n",
    "**2 - Select a date range (format 'YYYY-MM-DD')**\n",
    "\n",
    "**2 - Choose the criteria on which you want to base the best fit selection (rmse, r2, r).**\n",
    "\n",
    "- Choose between \"rmse\", \"r\", \"r2\"\n",
    "- If you choose \"r2\", you have to write \"max\"\n",
    "- \"min\" otherwise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595b3657-4171-4a33-9ad0-252d9bfa7252",
   "metadata": {},
   "source": [
    "## **Variables Description**\n",
    "\n",
    "We can divide the variables of this notebook in multiple categories: \n",
    "\n",
    "**Level 1:**\n",
    "- Variables to fit: Discharge and Precipitation\n",
    "- Variables Generated\n",
    "\n",
    "**Level 2:**\n",
    "Only for the variables generated.\n",
    "- Polynomial fit\n",
    "- Neural Network fit\n",
    "\n",
    "**Level 3:**\n",
    "- Reof\n",
    "- Training Data (stack of SAR or Water Mask images on which the fit is calculated, polarization VV, VH or both)\n",
    "- Filetype (SAR or Water Mask)\n",
    "- Polarization (VV, VH, VV & VH)\n",
    "- Coefficients (for polynomial fit only, coefficients of the best fitting polynomial)\n",
    "- Modes (for polynomial fit only, mode with the best fit to the variables to fit)\n",
    "- Models (for neural network only, model with the best variables fit)\n",
    "- Score (for polynomial only, to help decide which fit is the best)\n",
    "- RMSE (score for neural network to see which model is the best)\n",
    "- Reof_Forecast (reof of the images we forecasted)\n",
    "- Reof_Hindcast (reof of the images we hindcast to compare with forecast)\n",
    "- Hindcast (hindcast stack of images)\n",
    "- Forecast (forecast stack of images)\n",
    "- Best_Index (index of the best score)\n",
    "- Difference (difference of Reofs of forecast and hindcast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03790731-12e8-484b-b963-e1a39c05297e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of available dataset\n",
    "list_types = ['SAR','Water Mask']\n",
    "# List of available polarizations\n",
    "list_polarization = ['VH', 'VH and VV', 'VV']\n",
    "\n",
    "# Create the folder for the figures\n",
    "pathfig = Path(fc.selected)/'Figures'\n",
    "pathfig.mkdir(exist_ok=True)\n",
    "\n",
    "# Create a dictionnary to hold our many variables\n",
    "vz = {\n",
    "    key1: {\n",
    "        key2: {\n",
    "            sub_key: [] for sub_key in [\n",
    "                'Reof', 'Training_Data', 'Filetype', 'Polarization',\n",
    "                'Coeffs', 'Modes', 'Models', 'Score', 'RMSE', 'Reof_forecast',\n",
    "                'Reof_hindcast', 'Hindcast', 'Forecast', 'Best_Index', 'Difference'\n",
    "            ]\n",
    "        }\n",
    "        for key2 in ['Polynomial', 'Neural']\n",
    "    }\n",
    "    for key1 in ['Q', 'ERA']\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "# Load the time template, every file combination has the same\n",
    "tiff_dir = Path(fc.selected)/'RTC_GAMMA'\n",
    "tiffs = list(tiff_dir.glob(f'*VV.tif*'))\n",
    "\n",
    "times = get_dates(tiff_dir, '*VV')\n",
    "times.sort()\n",
    "times = pd.DatetimeIndex(times)\n",
    "times.name = \"time\"\n",
    "\n",
    "\n",
    "pathfig = Path(fc.selected)/'Figures'\n",
    "\n",
    "floodpercent = np.load(pathfig/\"flood_percentage.npy\")\n",
    "time_index = np.load(pathfig/\"time_index.npy\")\n",
    "time_index = pd.DatetimeIndex(time_index)\n",
    "plt.rcParams.update({'font.size': 12})\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9,5))\n",
    "\n",
    "ax.plot(np.unique(time_index), floodpercent, color='b', marker='o', markersize=3, label='Area Covered in Water [%]')\n",
    "ax.set_ylim([np.min(floodpercent)-np.min(floodpercent)*0.1, np.max(floodpercent)+np.min(floodpercent)*0.1])\n",
    "ax.set_xlabel('Date')\n",
    "ax.axhline(y=np.mean(floodpercent), color='k', linestyle='--', label='Average Water Coverage [%]')\n",
    "ax.set_ylabel('Image Area Covered in Water [%]')\n",
    "ax.grid()\n",
    "figname = ('ThresholdAndAreaTS.png')\n",
    "ax.legend(loc='lower right')\n",
    "plt.title(f\"Maximum water coverage on {time_index[np.argmax(floodpercent)].strftime('%Y-%m-%d')}, index: {np.argmax(floodpercent)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4f77cb-19d8-4018-b80c-c33c3c45880d",
   "metadata": {},
   "source": [
    "**Choose the time window for the forecast**\n",
    "Choose either a date range, or the index of the event you want to test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0669611c-8810-4523-a549-bf0f2fce5e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sdate = '2019-11-01'\n",
    "edate = '2019-12-15'\n",
    "#sdate = 128\n",
    "#edate = 130\n",
    "\n",
    "metricranking = ('r2','max')\n",
    "\n",
    "if type(sdate) is int:\n",
    "    start_ind = sdate\n",
    "    stop_ind = edate\n",
    "else:\n",
    "    start_ind = np.argmin(np.abs(times-pd.to_datetime(sdate)))\n",
    "    stop_ind = np.argmin(np.abs(times-pd.to_datetime(edate)))\n",
    "\n",
    "if start_ind == stop_ind or start_ind > stop_ind:\n",
    "    print('Please select other dates')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f609411b-9f94-4056-b7c0-27ec29563b6e",
   "metadata": {},
   "source": [
    "**Run the fit calculation for every polarization and dataset type available. This will help choosing which of water masks or SAR, VV/VH/VV&VH is the best combination**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc3331c5-0523-43c4-85a7-a716e100948f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Convert 'times' to a dataarray to use with match_dates()\n",
    "time_dataarray = xr.DataArray(np.array(times), dims='time', coords={'time': np.array(times)})\n",
    "\n",
    "# Create MATCH, the list gathering the discharge and precipitations\n",
    "mz = {\n",
    "    'Q': {\n",
    "        'Total': None,\n",
    "        'Selected': None,\n",
    "        'Forecast':None\n",
    "    },\n",
    "    'ERA': {\n",
    "        'Total': None,\n",
    "        'Selected': None,\n",
    "        'Forecast':None\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# Load in memory the discharge  dataset (will be the same everytime)\n",
    "lon,lat = get_centerpoint_coordinates(tiffs[0])\n",
    "mz['Q']['Total'] = fierpy.get_streamflow(lat,lon)[0]\n",
    "mz['Q']['Selected'] = fierpy.match_dates(mz['Q']['Total'], time_dataarray[:start_ind])\n",
    "\n",
    "\n",
    "# Get the projection of the AOI\n",
    "info = gdal.Info(str(tiffs[0]), format='json')\n",
    "info = info['coordinateSystem']['wkt']\n",
    "utm = info.split('ID')[-1].split(',')[1][0:-2]\n",
    "\n",
    "# Get the bounds of the AOI\n",
    "dataset = gdal.Open(str(tiffs[0]))\n",
    "if dataset is not None:\n",
    "    # Get the transformation information\n",
    "    transform = dataset.GetGeoTransform()\n",
    "\n",
    "    # Extract the corner coordinates\n",
    "    xmin = transform[0]\n",
    "    ymax = transform[3]\n",
    "    xmax = xmin + transform[1] * dataset.RasterXSize\n",
    "    ymin = ymax + transform[5] * dataset.RasterYSize\n",
    "\n",
    "from pyproj import Transformer\n",
    "points = [(ymin, xmin), (ymax, xmax)]  \n",
    "boundaries = []\n",
    "transformer = Transformer.from_crs(int(utm), 4326)\n",
    "for pt in transformer.itransform(points): boundaries.append(pt)\n",
    "boundaries = np.array(boundaries)\n",
    "\n",
    "# Open Dataarray\n",
    "era_ds = xr.open_dataarray(f\"{Path(fc.selected).parent}/ERA5/era5_data.nc\")\n",
    "\n",
    "# Get the closest lats and lons from the AOI's boundaries, otherwise slicing the dataset can return empty slices\n",
    "latmin = era_ds['latitude'].values[np.argmin(np.abs(era_ds['latitude'].values - boundaries[0][0]))]\n",
    "latmax = era_ds['latitude'].values[np.argmin(np.abs(era_ds['latitude'].values - boundaries[1][0]))]\n",
    "lonmin = era_ds['longitude'].values[np.argmin(np.abs(era_ds['longitude'].values - boundaries[0][1]))]\n",
    "lonmax = era_ds['longitude'].values[np.argmin(np.abs(era_ds['longitude'].values - boundaries[1][1]))]\n",
    "\n",
    "# Load in memory the precipitation dataset, fitted to the AOI, as a dataarray so it can use the match_dates function\n",
    "era_ds = era_ds.sel(longitude = slice(lonmin, lonmax), latitude = slice(latmax, latmin))\n",
    "# Convert to dataarray\n",
    "era_ds = xr.DataArray(np.sum(np.sum(era_ds.values,axis=1),axis=1), dims='time', coords={'time': era_ds.time.values})\n",
    "# Select the data corresponding to time\n",
    "era_sel = fierpy.match_dates(era_ds, time_dataarray[:start_ind]).fillna(0)\n",
    "\n",
    "mz['ERA']['Total'] = era_ds\n",
    "mz['ERA']['Selected'] = era_sel\n",
    "\n",
    "\n",
    "# Iterate through every dataset type and polarization to compute the fits with the discharge\n",
    "c = 1\n",
    "for filetype in list_types:\n",
    "    for polarization in list_polarization:\n",
    "        print(f\"Starting {filetype} {polarization}\")\n",
    "        # There is no VH&VV polarization for SAR so we skip the fitting\n",
    "        if filetype == 'SAR' and polarization == 'VH and VV':\n",
    "            append_all(vz, 'Coeffs', np.array([0,0,0]))\n",
    "            append_all(vz, 'Modes', 0)\n",
    "            # Depending on the metric and ranking we want to make sure the fake score is the worst\n",
    "            if metricranking[1] == 'min':\n",
    "                append_all(vz, 'Score', 1e9)\n",
    "            else:\n",
    "                append_all(vz, 'Score', 1e-9)\n",
    "                \n",
    "            # Do the same for the neural score\n",
    "            append_all(vz, 'RMSE', 1e9)\n",
    "            \n",
    "        else:\n",
    "            reof_ds, da, vv = looper(mz, filetype,\n",
    "                                            polarization,\n",
    "                                            start_ind,\n",
    "                                            metricranking,\n",
    "                                            vz,\n",
    "                                            fitting=True\n",
    "                                            )\n",
    "        print(f\"{c}/6 | Finished computing {filetype} {polarization}\")\n",
    "        c += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e9e8b69-28c1-4670-8244-dae7c0a89ba6",
   "metadata": {},
   "source": [
    "**Select the best mode and associated coefficients based on the ranking score**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72081115-f4e5-4b7c-8fee-953868789dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the index of the best score, best filetype and polarization from the polynomial fits\n",
    "\n",
    "for var in ['Q','ERA']:\n",
    "    if metricranking[1] == 'min':\n",
    "        vz[var]['Polynomial']['Best_Index'] = vz[var]['Polynomial']['Score'].index(min(vz[var]['Polynomial']['Score']))\n",
    "    else:\n",
    "        vz[var]['Polynomial']['Best_Index'] = vz[var]['Polynomial']['Score'].index(max(vz[var]['Polynomial']['Score']))\n",
    "    if vz[var]['Polynomial']['Best_Index'] < 3:\n",
    "        vz[var]['Polynomial']['Filetype'] = 'SAR'\n",
    "        vz[var]['Polynomial']['Polarization'] = list_polarization[vz[var]['Polynomial']['Best_Index']]\n",
    "    else:\n",
    "        vz[var]['Polynomial']['Filetype'] = 'Water_Mask'\n",
    "        vz[var]['Polynomial']['Polarization'] = list_polarization[vz[var]['Polynomial']['Best_Index']-3]\n",
    "        \n",
    "    # Do the same for the neural network\n",
    "    vz[var]['Neural']['Best_Index']  = vz[var]['Neural']['RMSE'].index(min(vz[var]['Neural']['RMSE']))\n",
    "    if vz[var]['Neural']['Best_Index'] < 3:\n",
    "        vz[var]['Neural']['Filetype'] = 'SAR'\n",
    "        vz[var]['Neural']['Polarization'] = list_polarization[vz[var]['Neural']['Best_Index']]\n",
    "    else:\n",
    "        vz[var]['Neural']['Filetype'] = 'Water_Mask'\n",
    "        vz[var]['Neural']['Polarization'] = list_polarization[vz[var]['Neural']['Best_Index']-3]\n",
    "\n",
    "    # Replace the coeffs, modes and models by their best iteration\n",
    "    vz[var]['Polynomial']['Coeffs'] = np.array(vz[var]['Polynomial']['Coeffs'][vz[var]['Polynomial']['Best_Index']])\n",
    "    vz[var]['Polynomial']['Modes'] = vz[var]['Polynomial']['Modes'][vz[var]['Polynomial']['Best_Index']]\n",
    "    vz[var]['Neural']['Models'] = vz[var]['Neural']['Models'][vz[var]['Neural']['Best_Index']]\n",
    "    \n",
    "    # Calculate the reof of the best combination of polarization and filetype\n",
    "    vz[var]['Polynomial']['Reof'], vz[var]['Polynomial']['Training_Data'], *_ = looper(mz, vz[var]['Polynomial']['Filetype'], vz[var]['Polynomial']['Polarization'], start_ind, metricranking, vz, fitting = False)\n",
    "    vz[var]['Polynomial']['Hindcast'] = vz[var]['Polynomial']['Training_Data'][start_ind:stop_ind+1]\n",
    "    vz[var]['Neural']['Reof'], vz[var]['Neural']['Training_Data'], *_ = looper(mz, vz[var]['Neural']['Filetype'], vz[var]['Neural']['Polarization'], start_ind, metricranking, vz, fitting = False)\n",
    "    vz[var]['Neural']['Hindcast'] = vz[var]['Neural']['Training_Data'][start_ind:stop_ind+1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cedf1de5-cc44-49da-853a-df76e85b9e70",
   "metadata": {},
   "source": [
    "**Prepare the datasets for the fit**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "902fd569-cdf2-4f58-8953-d129e0cda473",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We fill in the NaNs to avoid breaking the fit\n",
    "for var, reg in zip(['Q','ERA'],['Polynomial','Neural']):\n",
    "    vz[var][reg]['Reof'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "291113e3-b8e3-4847-97b2-fc367709affa",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,5), ncols=2)\n",
    "xlabels = ['Discharge [$m^{3}.s^{-1}$]', 'Precipitations [m.h^{-1}]']\n",
    "for var, i in zip(['Q','ERA'],range(2)):\n",
    "    vals = vz[var]['Polynomial']\n",
    "    x = np.linspace(0, mz[var]['Selected'].max(),100)\n",
    "    f = np.poly1d(np.squeeze(vals['Coeffs']))\n",
    "    ax[i].plot(mz[var]['Selected'],vals['Reof'].temporal_modes[:,vals['Modes']-1], 'o', label=f\"{metricranking[0]} = {np.round(vals['Score'][vals['Best_Index']],5)}\")\n",
    "    ax[i].legend()\n",
    "    ax[i].set_xlabel(xlabels[i])\n",
    "    ax[i].set_ylabel('Time series amplitude')\n",
    "    ax[i].plot(x,f(x))\n",
    "    ax[i].set_title(f\"Fit for mode {vals['Modes']}, poly degree {len(vals['Coeffs'])-1}, {vals['Filetype']}_{vals['Polarization']}\")            \n",
    "plt.savefig(pathfig/f'Polynomial_Fit_{times[0].strftime('%Y-%m-%d')}_{times[start_ind].strftime('%Y-%m-%d')}.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bdbb9f-ba26-45c6-ac65-d8fecc1a9576",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(constrained_layout=True, figsize=(20, 10))\n",
    "\n",
    "row_titles = [f\"Discharge | {vz['Q']['Neural']['Filetype']}_{vz['Q']['Neural']['Polarization']}, RMSE: {min(vz['Q']['Neural']['RMSE']):.3f}\",\n",
    "              f\"Precipitation | {vz['ERA']['Neural']['Filetype']}_{vz['ERA']['Neural']['Polarization']}, RMSE: {min(vz['ERA']['Neural']['RMSE']):.3f}\"]\n",
    "\n",
    "# Create 3x1 subfigs\n",
    "subfigs = fig.subfigures(nrows=2, ncols=1)\n",
    "\n",
    "for var, i in zip(['Q','ERA'],range(2)):\n",
    "    subfigs[i].suptitle(f'{row_titles[i]}')\n",
    "\n",
    "    # Create 1x3 subplots per subfig\n",
    "    axs = subfigs[i].subplots(nrows=1, ncols=4)\n",
    "    axs[i].set_ylabel('Temporal Mode Amplitude', color='black')\n",
    "    axs[i].yaxis.set_label_coords(-0.2, 0.5)\n",
    "    for col, ax in enumerate(axs):\n",
    "        ax.scatter(mz[var]['Selected'], vz[var]['Neural']['Reof'].temporal_modes[:, col], label='Hindcast')\n",
    "        ax.plot(mz[var]['Selected'], vz[var]['Neural']['Models'][col].predict(mz[var]['Selected'].values), label='Model', color='orange')\n",
    "        ax.set_title(f'Temporal Mode {col+1}')\n",
    "        ax.set_xlabel(xlabels[i])\n",
    "        ax.legend()\n",
    "fig.savefig(pathfig/f\"Neural_fit_{times[0].strftime('%Y-%m-%d')}_{times[start_ind].strftime('%Y-%m-%d')}.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7854be79-5570-4bae-8a61-5d987b19271b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "width_per_subplot = 5  # Desired width (in inches) for each subplot\n",
    "num_columns = len(vz[var]['Polynomial']['Reof'].mode.values)\n",
    "fig_width = num_columns * width_per_subplot\n",
    "\n",
    "fig = plt.figure(constrained_layout=True, figsize=(fig_width, 10))\n",
    "\n",
    "labels = ['Discharge','Precipitation']\n",
    "# Create 3x1 subfigs\n",
    "subfigs = fig.subfigures(nrows=2, ncols=1)\n",
    "\n",
    "for var, i in zip(['Q','ERA'],range(2)):\n",
    "    subfigs[i].suptitle(f'{row_titles[i]}')\n",
    "\n",
    "    # Create 1x3 subplots per subfig\n",
    "    axs = subfigs[i].subplots(nrows=1, ncols=4)\n",
    "    axs[i].set_ylabel('Normalized Values', color='black')\n",
    "    axs[i].yaxis.set_label_coords(-0.2, 0.5)\n",
    "    \n",
    "    for col, ax in enumerate(axs):\n",
    "        reof_norm = normalize(vz[var]['Polynomial']['Reof'].temporal_modes[:, col])\n",
    "        vari = normalize(mz[var]['Selected'])\n",
    "        # Plotting the data with modified labels and line styles\n",
    "        ax.plot(times[:start_ind], (reof_norm - np.min(reof_norm)) / (np.max(reof_norm) - np.min(reof_norm)),\n",
    "                        label='RTPC', linestyle='-', linewidth=2, color='black')  # RTPC - Red solid line\n",
    "        ax.plot(times[:start_ind], (vari - np.min(vari)) / (np.max(vari) - np.min(vari)),\n",
    "                        label=labels[i], linestyle='--', linewidth=2, dashes=(5, 2), color='blue')  # Discharge - Dashed line\n",
    "        ax.set_xlabel('Times')  # X-axis label\n",
    "        ax.set_ylabel('Normalized Values')  # Y-axis label\n",
    "        corr, _ = pearsonr(reof_norm, vari)\n",
    "        ax.set_title(f'Mode {col+1} (Correlation: {corr:.3f})', fontsize=20)  # Subplot title with correlation\n",
    "        ax.legend(fontsize=17)  # Show legend\n",
    "        ax.tick_params(axis='x', rotation=45)  # Rotate x-axis tick labels by 45 degrees\n",
    "\n",
    "\n",
    "#plt.tight_layout()  # Adjust the layout spacing\n",
    "plt.show()  # Display the plot\n",
    "plt.savefig(pathfig/f\"Variables_Modes_Correlations_{times[0].strftime('%Y-%m-%d')}_{times[start_ind].strftime('%Y-%m-%d')}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57b2ad72-d9e5-4c1c-b833-0f297cf989d3",
   "metadata": {},
   "source": [
    "**Plot the spatiotemporal modes for the discharge** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1daf199c-f21f-4232-a49c-17f4df28b2cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open figure based on amount of modes\n",
    "\n",
    "\n",
    "fp = []\n",
    "plot = True \n",
    "\n",
    "for reg, p in zip(['Polynomial','Neural'], range(2)):\n",
    "    for var, j in zip(['Q','ERA'],range(2)):\n",
    "        fp.append(f\"{vz[var][reg]['Filetype']}{vz[var][reg]['Polarization']}\")\n",
    "        \n",
    "        # If True, the figure generation is skipped\n",
    "        if p >= 1 and f\"{vz[var][reg]['Filetype']}{vz[var][reg]['Polarization']}\" == fp[(j+p)-2]:\n",
    "            plot = False\n",
    "        else:\n",
    "            True\n",
    "        if plot:            \n",
    "            reof = vz[var][reg]['Reof']\n",
    "            plt.figure()\n",
    "            num_columns = len(reof.mode.values)  # Number of columns in your subplots\n",
    "            width_per_subplot = 5  # Desired width (in inches) for each subplot\n",
    "\n",
    "            fig_width = num_columns * width_per_subplot\n",
    "\n",
    "            fig, axes = plt.subplots(nrows=2, ncols=num_columns, figsize=(fig_width, 10))\n",
    "            fig.suptitle(f\"{reg} - {var} | Modes from {times[0].strftime('%Y-%m-%d')} to {times[start_ind].strftime('%Y-%m-%d')}, {vz[var][reg]['Filetype']} {vz[var][reg]['Polarization']}\", fontsize=22)\n",
    "            # This part plots the spatial modes\n",
    "            for i, ax in enumerate(axes[0]):\n",
    "\n",
    "                # Create a plot of the spatial modes\n",
    "                mesh = ax.imshow(reof.spatial_modes.values[:,:,i],\n",
    "                          cmap = 'icefire',\n",
    "                          vmin = -np.nanstd(reof.spatial_modes.values[:,:,i])/2+np.nanmean(reof.spatial_modes.values[:,:,i]),\n",
    "                          vmax = np.nanstd(reof.spatial_modes.values[:,:,i])/2+np.nanmean(reof.spatial_modes.values[:,:,i]))\n",
    "\n",
    "                # Set plot title and labels\n",
    "                ax.set_title(f\"Spatial Mode {i}\")\n",
    "\n",
    "                # Add colorbar\n",
    "                imratio=0.047*(reof.spatial_modes.values[:,:,i].shape[0]/reof.spatial_modes.values[:,:,i].shape[1])\n",
    "                cbar0 = fig.colorbar(mesh, ax=ax, fraction=imratio)\n",
    "                cbar0.set_label('Spatial Mode Value')\n",
    "\n",
    "            # This part plots the temporal modes with the discharge superimposed\n",
    "            for i, ax in enumerate(axes[1]):\n",
    "                # Create a line plot of the temporal mode\n",
    "                ax.scatter(times[:start_ind], reof.temporal_modes[:, i], color = 'red', label='Temporal Modes', s = 150)\n",
    "                # Format x-tick labels as dates\n",
    "                ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "                ax.xaxis.set_minor_locator(mdates.AutoDateLocator())\n",
    "                # Rotate x-tick labels\n",
    "                plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)\n",
    "                # Set plot title and labels\n",
    "                ax.set_title(f\"Temporal Mode {i}\")\n",
    "                ax.set_xlabel('Time')\n",
    "                ax.set_ylabel('Amplitude')\n",
    "\n",
    "                # Create a secondary y-axis on the right\n",
    "                ax_secondary = ax.twinx()\n",
    "\n",
    "                # Plot the secondary data as bars on the right axis\n",
    "                ax_secondary.bar(times[:start_ind], mz[var]['Selected'].values, color='blue', alpha=0.5, label = labels[j])\n",
    "                ax_secondary.set_ylabel(xlabels[j])\n",
    "\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "            plt.savefig(pathfig/f\"{reg[0]}_Reof_{var}_{times[0].strftime('%Y-%m-%d')}_{times[start_ind].strftime('%Y-%m-%d')}.png\", dpi = 400)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c794508b-f169-4ddc-946b-df31762489e3",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76f0a7cc-133e-421e-946a-4001c70a2604",
   "metadata": {},
   "source": [
    "#### **Calculate the forecast of flooding based on the relationship between discharge and the main modes of our dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25bce77b-cd80-41f6-bbb9-f4b33a236a7a",
   "metadata": {},
   "source": [
    "**Calculate the amount of days between sdate and edate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f73581bf-0e9a-4b88-9d0a-725b9aeb7b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Amount of days for the forecast\n",
    "nb_days_forecast = (times[stop_ind] - times[start_ind]).days"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cd0d1b2-cdb4-4f13-b20d-6a53c4d1b255",
   "metadata": {},
   "source": [
    "**Generate the forecast based on the best fit coefficients**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5320793-02e3-45c1-afe6-0927905eb8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new dates array nb_days_forecast days into the future and save them as a dataset\n",
    "forecast_dates = xr.Dataset.from_dataframe(\n",
    "                    pd.DataFrame(\n",
    "                        {'time': da[:start_ind].time.max().values +\n",
    "                         np.arange(1, nb_days_forecast+1, dtype='timedelta64[D]')}\n",
    "                    )\n",
    "                    )\n",
    "\n",
    "for var in ['Q','ERA']:\n",
    "    mz[var]['Forecast'] = fierpy.match_dates(mz[var]['Total'],forecast_dates)\n",
    "    \n",
    "    for reg in ['Polynomial','Neural']:\n",
    "        # Use the previously found relationships and functions to generate RTC/mask forecast\n",
    "        vz[var]['Polynomial']['Forecast'] = fierpy.synthesize(vz[var]['Polynomial']['Reof'],\n",
    "                                                              mz[var]['Forecast'],\n",
    "                                                              np.poly1d(vz[var]['Polynomial']['Coeffs']),\n",
    "                                                              vz[var]['Polynomial']['Modes'])\n",
    "        \n",
    "        vz[var]['Neural']['Forecast'] = synthesize_neural(mz[var]['Forecast'],\n",
    "                                                          vz[var]['Neural']['Models'],\n",
    "                                                          vz[var]['Neural']['Reof'],\n",
    "                                                          vz[var]['Polynomial']['Forecast'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f49ed3-570d-4adb-afc7-12f31ba1c358",
   "metadata": {},
   "source": [
    "**Grab overlapping dates between forecast and dataset to compare the forecast quality**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f257b7ed-0ad4-4ee3-9788-25a20dc746e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the matching indices\n",
    "ind_hindcast = np.where(np.isin( vz[var]['Polynomial']['Hindcast']['time'].values, vz[var]['Polynomial']['Forecast']['time'].values))[0]\n",
    "ind_forecast = np.where(np.isin( vz[var]['Polynomial']['Forecast']['time'].values, vz[var]['Polynomial']['Hindcast']['time'].values))[0]\n",
    "\n",
    "# Grab the slices of the datasets corresponding to the matching indices\n",
    "for var in ['Q','ERA']:\n",
    "    for reg in ['Polynomial','Neural']:\n",
    "        vz[var][reg]['Forecast'] = vz[var][reg]['Forecast'].isel(time=ind_forecast)\n",
    "        vz[var][reg]['Hindcast'] = vz[var][reg]['Hindcast'].isel(time=ind_hindcast)\n",
    "        vz[var][reg]['Difference']  = vz[var][reg]['Forecast']  - vz[var][reg]['Hindcast'] # Calculate the differences between the forecast and hindcast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f0fc65-cc9d-4f52-a5f3-6479751856da",
   "metadata": {},
   "source": [
    "### **Z-Score for the forecasts**\n",
    "\n",
    "**Calculate the forecasts' scores compared to the hindcasts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f306a89-26fd-48c2-bf40-d6ce7fb0c699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the arrays to host the scores results\n",
    "CSI=np.zeros((4))\n",
    "Overall = np.zeros((4))\n",
    "\n",
    "# Calculate the scores\n",
    "i = 0\n",
    "for var in ['Q','ERA']:\n",
    "    for reg in ['Polynomial','Neural']:\n",
    "        CSI[i], Overall[i] = z_score(vz[var][reg]['Training_Data'] , mz[var]['Selected'], vz[var][reg]['Forecast'] , vz[var][reg]['Hindcast'] ,3)\n",
    "        i += 1\n",
    "\n",
    "# Define the row and column labels\n",
    "row_labels = ['Discharge', 'Precipitation']\n",
    "column_labels = ['Polynomial', 'Neural']\n",
    "\n",
    "# Create a figure and axis\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot the matrix using imshow\n",
    "im = ax.imshow(np.vstack((CSI,Overall)).mean(axis=0).reshape((2,2)), cmap='Blues')\n",
    "\n",
    "# Add ticks and labels to the x-axis and y-axis\n",
    "ax.set_xticks(np.arange(len(column_labels)))\n",
    "ax.set_yticks(np.arange(len(row_labels)))\n",
    "ax.set_xticklabels(column_labels)\n",
    "ax.set_yticklabels(row_labels)\n",
    "\n",
    "# Loop over the data to add text annotations in each cell\n",
    "for i in range(len(row_labels)):\n",
    "    for j in range(len(column_labels)):\n",
    "        text = ax.text(j, i, f\"CSI: {CSI[i+j]:.2f}\\nTot: {Overall[i+j]:.2f}\", ha='center', va='center', color='red')\n",
    "\n",
    "# Set the title\n",
    "ax.set_title(\"Forecast Scores\")\n",
    "\n",
    "# Add a colorbar\n",
    "cbar = ax.figure.colorbar(im, label='Average score [%]')\n",
    "\n",
    "# Show the plot\n",
    "plt.show()\n",
    "\n",
    "plt.savefig(pathfig/f\"Scores_{times[0].strftime('%Y-%m-%d')}_{times[start_ind].strftime('%Y-%m-%d')}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df73188-87c2-4ca9-a785-2a1f8d714faa",
   "metadata": {},
   "source": [
    "### **Plot the forecasts and their associated real data to compare spatial correspondance**\n",
    "*The colorbar is adjusted to the values of each normalized dataset. We use as colorbar boundaries:\n",
    "$\\mu(\\text{dataset})\\pm\\sigma(\\text{dataset})$*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43a98f42-2198-45fb-9cd8-f99485f4b707",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically set the size of the plot\n",
    "\n",
    "names = ['Discharge','','Precipitation']\n",
    "\n",
    "nrows = 4\n",
    "width_ratios = [1] * ncols  # Equal width for subplots, and additional space for colorbar\n",
    "width_ratios[-1] += 0.075\n",
    "height_ratios = [1] * nrows\n",
    "\n",
    "for reg, r in zip(['Polynomial', 'Neural'], range(2)):\n",
    "    \n",
    "    num_columns = len(vz['Q'][reg]['Forecast'].time)  # Number of columns in your subplots\n",
    "    if num_columns <= 1:\n",
    "        ncols = 2\n",
    "        max_iter = 1\n",
    "    else:\n",
    "        ncols = num_columns\n",
    "        max_iter = ncols\n",
    "\n",
    "    width_per_subplot = 5  # Desired width (in inches) for each subplot\n",
    "    fig_width = num_columns * width_per_subplot\n",
    "\n",
    "    # Start Figure\n",
    "    fig, ax = plt.subplots(figsize=(fig_width, 15), nrows = 4, ncols = ncols, gridspec_kw={'width_ratios': width_ratios, 'height_ratios': height_ratios})\n",
    "    \n",
    "    # Create title\n",
    "    fig.suptitle(f\"Q: {vz[var][reg]['Filetype']} {vz[var][reg]['Polarization']}, mode {vz[var][reg]['Modes']}, poly deg {len(vz[var][reg]['Coeffs'])-1} | Prec: {vz[var][reg]['Filetype']} {vz[var][reg]['Polarization']}, mode {vz[var][reg]['Modes']}, poly deg{len(vz[var][reg]['Coeffs'])-1}\", fontsize = 20)\n",
    "\n",
    "    \n",
    "    for var, j in zip(['Q', 'ERA'], [0,2]):\n",
    "        forecast = vz[var][reg]['Forecast'].fillna(0)\n",
    "        hindcast = vz[var][reg]['Hindcast'].fillna(0)\n",
    "\n",
    "\n",
    "        # Loop to plot the data. We use the forecast and their associated real data, normalized\n",
    "        # The colorbar is varying from -std+mean to std+mean\n",
    "        for i in range(max_iter):\n",
    "            norm_hind = normalize(hindcast[i])\n",
    "            norm_fore = normalize(forecast[i])\n",
    "\n",
    "            im0 = ax[j,i].imshow(norm_hind, vmin = -norm_hind.std() + norm_hind.mean(), vmax = norm_hind.std() + norm_hind.mean())\n",
    "            ax[0,i].set_title(f\"{str(norm_hind[i].time.values)[0:10]}, f{ind_forecast[i]}\", fontsize = 17)\n",
    "            im1 = ax[j+1,i].imshow(norm_fore, vmin = -norm_fore.std() + norm_fore.mean(), vmax = norm_fore.std() + norm_fore.mean())\n",
    "\n",
    "            ax[j,i].set_xticks([])\n",
    "            ax[j,i].set_yticks([])\n",
    "            ax[j+1,i].set_xticks([])\n",
    "            ax[j+1,i].set_yticks([])\n",
    "            \n",
    "            ax[j,0].set_ylabel(f\"Hindcast {vz[var][reg]['Filetype']} {vz[var][reg]['Polarization']}\", fontsize = 15)\n",
    "            ax[j+1,0].set_ylabel(f\"Forecast {vz[var][reg]['Filetype']} {vz[var][reg]['Polarization']}\", fontsize = 15)\n",
    "            \n",
    "            if i == max_iter-1:\n",
    "\n",
    "                imratio=0.047*(norm_hind.shape[0]/norm_hind.shape[1])\n",
    "                cbar0 = fig.colorbar(im0, ax=ax[j,i], fraction=imratio)\n",
    "                cbar1 = fig.colorbar(im1, ax=ax[j+1,i], fraction=imratio)\n",
    "                cbar0.set_label('Normalized Frobenius Norm')\n",
    "                cbar1.set_label('Normalized Frobenius Norm')\n",
    "\n",
    "    # Remove the second column of ax if it is empty\n",
    "    if num_columns <= 1:\n",
    "        for i in range(len(ax)):\n",
    "            fig.delaxes(ax[i][1])\n",
    "\n",
    "    # rearange the axes for no overlap\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Plot line in the middle\n",
    "    line = plt.Line2D([0,1],[0.48,0.48], transform=fig.transFigure, color=\"red\")\n",
    "    # Create the first title for the first two rows\n",
    "    title1 = fig.text(0, 0.75, 'Discharge', va='center', ha='center', rotation='vertical', color='red', fontsize = 20)\n",
    "\n",
    "    # Create the second title for the last two rows\n",
    "    title2 = fig.text(0, 0.25, 'Precipitations', va='center', ha='center', rotation='vertical', color='red', fontsize = 20)\n",
    "\n",
    "    fig.add_artist(line)\n",
    "\n",
    "\n",
    "    plt.savefig(pathfig/f\"{reg[0]}_Forecat_Hindcast_Comparison_{names[j]}_{times[0].strftime('%Y-%m-%d')}_{times[start_ind].strftime('%Y-%m-%d')}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69aa9093-b973-4632-a0ac-87c98bb463e5",
   "metadata": {},
   "source": [
    "### Pattern analysis\n",
    "\n",
    "**Calculate the principal modes (REOFs) of the forecast and real data to compare them**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9a523e-c91a-4808-b0b6-f57ad1afac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Reofs forecasts and their real equivalents\n",
    "\n",
    "for var in ['Q','ERA']:\n",
    "    for reg in ['Polynomial','Neural']:\n",
    "        vz[var][reg]['Reof_Hindcast'] = freof(vz[var][reg]['Hindcast'], n_modes = vz[var][reg]['Hindcast'].shape[0])\n",
    "        vz[var][reg]['Reof_Forecast'] = freof(vz[var][reg]['Forecast'], n_modes = vz[var][reg]['Forecast'].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1b3e15-ca37-40b5-9a33-314e0a42d364",
   "metadata": {},
   "source": [
    "**Normalize the REOFs for comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f09ca0-d829-4fdb-95b2-3565e5ace3b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each entry add the differences to the dictionary\n",
    "for var in vz:\n",
    "    for reg in vz[var]:\n",
    "        vz[var][reg]['Reof_Diff_Spatial'] = xr.apply_ufunc(normalize, vz[var][reg]['Reof_Forecast'].spatial_modes) - xr.apply_ufunc(normalize, vz[var][reg]['Reof_Hindcast'].spatial_modes) # Difference of normalized reof spatial modes forecast/hindscast\n",
    "        vz[var][reg]['Reof_Diff_Temporal'] = xr.apply_ufunc(normalize, vz[var][reg]['Reof_Forecast'].temporal_modes) - xr.apply_ufunc(normalize, vz[var][reg]['Reof_Hindcast'].temporal_modes) #  Difference of normalized reof temporal modes forecast/hindscast\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509f3cd1-8d4f-42ce-9f00-55154fa0ee76",
   "metadata": {},
   "source": [
    "**Plot the differences between the REOFs of forecasts and real data**\n",
    "\n",
    "We use as colorbar boundaries:\n",
    "$\\mu(\\text{dataset})\\pm\\sigma(\\text{dataset})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de11242-daff-4973-ae0b-339dd01d2e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for reg, r in zip(['Polynomial', 'Neural'], range(2)):\n",
    "    \n",
    "    num_columns = len(vz['Q'][reg]['Forecast'].time)  # Number of columns in your subplots\n",
    "    if num_columns <= 1:\n",
    "        ncols = 2\n",
    "        max_iter = 1\n",
    "    else:\n",
    "        ncols = num_columns\n",
    "        max_iter = ncols\n",
    "\n",
    "    width_per_subplot = 5  # Desired width (in inches) for each subplot\n",
    "    fig_width = num_columns * width_per_subplot\n",
    "    \n",
    "    plt.figure()\n",
    "    # Start Figure\n",
    "    fig, ax = plt.subplots(figsize=(fig_width, 15), nrows = 4, ncols = ncols)\n",
    "    \n",
    "    # Create title\n",
    "    fig.suptitle(f\"Difference REOFs Forecast-Hindcast | Q: {vz[var][reg]['Filetype']} {vz[var][reg]['Polarization']}, mode {vz[var][reg]['Modes']}, poly deg {len(vz[var][reg]['Coeffs'])-1} | Prec: {vz[var][reg]['Filetype']} {vz[var][reg]['Polarization']}, mode {vz[var][reg]['Modes']}, poly deg{len(vz[var][reg]['Coeffs'])-1}\", fontsize = 20)\n",
    "\n",
    "    \n",
    "    for var, j in zip(['Q', 'ERA'], [0,2]):\n",
    "        \n",
    "        # Load the differences of the normalized spatiotemporal modes\n",
    "        spatial = vz[var][reg]['Reof_Diff_Spatial']\n",
    "        temporal = vz[var][reg]['Reof_Diff_Temporal']\n",
    "\n",
    "\n",
    "        # Loop to plot the data. We use the forecast and their associated real data, normalized\n",
    "        # The colorbar is varying from -std+mean to std+mean\n",
    "        for i in range(max_iter):\n",
    "\n",
    "            # Plot the spatial modes\n",
    "            ax[j,i].imshow(spatial.values[:,:,i],\n",
    "              cmap = 'icefire',\n",
    "              vmin = -np.nanstd(spatial.values[:,:,i])+np.nanmean(spatial.values[:,:,i]),\n",
    "              vmax = np.nanstd(spatial.values[:,:,i])+np.nanmean(spatial.values[:,:,i]))\n",
    "            \n",
    "            # Set plot title and labels\n",
    "            ax[j,i].set_title(f\"Spatial Mode {i+1}\")\n",
    "\n",
    "            # Add colorbar\n",
    "            cbar = fig.colorbar(mesh, ax=ax[j,i])\n",
    "\n",
    "            # Create a line plot of the temporal mode\n",
    "            ax[j+1,i].scatter(times[ind_forecast], temporal[:, i], color = 'red', label='Temporal Modes', s = 150)\n",
    "            # Format x-tick labels as dates\n",
    "            ax[j+1,i].xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d'))\n",
    "            ax[j+1,i].xaxis.set_minor_locator(mdates.AutoDateLocator())\n",
    "            # Rotate x-tick labels\n",
    "            plt.setp(ax[j+1,i].xaxis.get_majorticklabels(), rotation=45)\n",
    "            # Set plot title and labels\n",
    "            ax[j+1,i].set_title(f\"Temporal Mode {i + 1}\")\n",
    "            ax[j+1,i].set_xlabel('Time')\n",
    "            ax[j+1,i].set_ylabel('Amplitude')                      \n",
    "\n",
    "\n",
    "\n",
    "    # rearange the axes for no overlap\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # Plot line in the middle\n",
    "    line = plt.Line2D([0,1],[0.47,0.47], transform=fig.transFigure, color=\"red\")\n",
    "    \n",
    "    # Create the first title for the first two rows\n",
    "    title1 = fig.text(0.01, 0.75, 'Discharge', va='center', ha='center', rotation='vertical', color='red', fontsize = 20)\n",
    "\n",
    "    # Create the second title for the last two rows\n",
    "    title2 = fig.text(0.01, 0.25, 'Precipitations', va='center', ha='center', rotation='vertical', color='red', fontsize = 20)\n",
    "    fig.add_artist(line)\n",
    "\n",
    "    plt.savefig(pathfig/f\"{reg[0]}_Difference_REOFs_Forecast_Hindcast_{names[j]}_{times[0].strftime('%Y-%m-%d')}_{times[start_ind].strftime('%Y-%m-%d')}.png\")\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50095747-27b3-4c2a-9bb3-b331c249ac33",
   "metadata": {},
   "source": [
    "### **Frobenius norm of the spatial REOFs differences**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd539d7-1f14-46d3-99e5-1180cb57cec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "width_per_subplot = 5  # Desired width (in inches) for each subplot\n",
    "fig_width = 2 * width_per_subplot\n",
    "\n",
    "# Start Figure\n",
    "fig, ax = plt.subplots(figsize=(fig_width, 15), nrows = 4, ncols = 1)\n",
    "\n",
    "# Create title\n",
    "fig.suptitle(f\"Frobenius norm Difference REOFs Forecast-Hindcast\", fontsize = 20)\n",
    "\n",
    "\n",
    "for reg, j in zip(['Polynomial', 'Neural'], [0,2]):\n",
    "\n",
    "    # Load the differences of the normalized spatiotemporal modes\n",
    "    f1 = np.linalg.norm(vz['Q'][reg]['Reof_Diff_Spatial'], axis=2)\n",
    "    f2 = np.linalg.norm(vz['ERA'][reg]['Reof_Diff_Spatial'], axis = 2)\n",
    "\n",
    "\n",
    "    # Loop to plot the data. We use the forecast and their associated real data, normalized\n",
    "    # The colorbar is varying from -std+mean to std+mean\n",
    "    im0 = ax[j].imshow(f1, vmin=-np.std(f1) + np.mean(f1), vmax=np.std(f1) + np.mean(f1))\n",
    "    cbar0 = fig.colorbar(im0, ax=ax[j], shrink=1.0)\n",
    "    cbar0.set_label('Frobenius norm value')\n",
    "\n",
    "    ax[j].set_title('Discharge difference')\n",
    "\n",
    "    # Plot the second matrix with colorbar and title\n",
    "    im1 = ax[j+1].imshow(f2, vmin=-np.std(f2) + np.mean(f2), vmax=np.std(f2) + np.mean(f2))\n",
    "    cbar1 = fig.colorbar(im1, ax=ax[j+1], shrink=1.0)\n",
    "    cbar1.set_label('Frobenius norm value')\n",
    "\n",
    "    ax[j+1].set_title('Precipitation difference')\n",
    "\n",
    "    # Set the title for the entire figure\n",
    "    fig.suptitle('Frobenius norm of spatial modes difference between forecast and real data')\n",
    "\n",
    "\n",
    "# rearange the axes for no overlap\n",
    "fig.tight_layout()\n",
    "\n",
    "# Plot line in the middle\n",
    "line = plt.Line2D([0,1],[0.49,0.49], transform=fig.transFigure, color=\"red\")\n",
    "\n",
    "# Create the first title for the first two rows\n",
    "title1 = fig.text(0.001, 0.75, 'Polynomial', va='center', ha='center', rotation='vertical', color='red', fontsize = 20)\n",
    "\n",
    "# Create the second title for the last two rows\n",
    "title2 = fig.text(0.001, 0.25, 'Neural', va='center', ha='center', rotation='vertical', color='red', fontsize = 20)\n",
    "fig.add_artist(line)\n",
    "\n",
    "plt.savefig(pathfig/f\"Frobenius_Difference_Forecast_Hindcast_{times[0].strftime('%Y-%m-%d')}_{times[start_ind].strftime('%Y-%m-%d')}.png\", dpi = 400)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad906e3b-8612-494d-ad8c-7f9f75a78e4c",
   "metadata": {},
   "source": [
    "### **Gradient and Fourier Transform for spatial comparison**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429a55e5-97dc-451b-90e8-de5a4db31991",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import convolve\n",
    "from scipy.fft import fft2, fftshift\n",
    "\n",
    "nrows = 4\n",
    "width_ratios = [1] * ncols  # Equal width for subplots, and additional space for colorbar\n",
    "width_ratios[-1] += 0.075\n",
    "height_ratios = [1] * nrows\n",
    "\n",
    "for reg in ['Polynomial', 'Neural']:\n",
    "    #Automatically set the size of the plot\n",
    "    # Start Figures\n",
    "    fig1, ax1 = plt.subplots(figsize=(fig_width, 15), nrows = 4, ncols = ncols, gridspec_kw={'width_ratios': width_ratios, 'height_ratios': height_ratios})\n",
    "    fig2, ax2 = plt.subplots(figsize=(fig_width, 15), nrows = 4, ncols = ncols, gridspec_kw={'width_ratios': width_ratios, 'height_ratios': height_ratios})\n",
    "\n",
    "\n",
    "    # Create title\n",
    "    fig1.suptitle(f\"{reg} | Q: {vz['Q'][reg]['Filetype']} {vz['Q'][reg]['Polarization']}, mode {vz['Q'][reg]['Modes']}, poly deg {len(vz['Q'][reg]['Coeffs'])-1} | Prec: {vz['ERA'][reg]['Filetype']} {vz['ERA'][reg]['Polarization']}, mode {vz['ERA'][reg]['Modes']}, poly deg{len(vz['ERA'][reg]['Coeffs'])-1}\", fontsize = 20)\n",
    "    fig2.suptitle(f\"{reg} | Q: {vz['Q'][reg]['Filetype']} {vz['Q'][reg]['Polarization']}, mode {vz['Q'][reg]['Modes']}, poly deg {len(vz['Q'][reg]['Coeffs'])-1} | Prec: {vz['ERA'][reg]['Filetype']} {vz['ERA'][reg]['Polarization']}, mode {vz['ERA'][reg]['Modes']}, poly deg{len(vz['ERA'][reg]['Coeffs'])-1}\", fontsize = 20)\n",
    "\n",
    "    # Loop to plot the data. We use the forecast and their associated real data, normalized\n",
    "    # The colorbar is varying from -std+mean to std+mean\n",
    "    \n",
    "    for var, j in zip(['Q', 'ERA'], [0,2]):\n",
    "        for i in range(max_iter):\n",
    "\n",
    "\n",
    "            # Compute the gradients using finite differences\n",
    "            dhind = np.gradient(vz[var][reg]['Hindcast'].values[i])\n",
    "            dfore = np.gradient(vz[var][reg]['Forecast'].values[i])\n",
    "\n",
    "            # Compute the magnitude of gradients\n",
    "            dmag_hind = np.sqrt(dhind[0] ** 2 + dhind[1] ** 2)\n",
    "            dmag_fore = np.sqrt(dfore[0] ** 2 + dfore[1] ** 2)\n",
    "\n",
    "            # Normalize the gradients\n",
    "            dmag_hind = normalize(dmag_hind)\n",
    "            dmag_fore = normalize(dmag_fore)\n",
    "\n",
    "            # Perform Fourier transform\n",
    "            ffthind = fftshift(fft2(vz[var][reg]['Hindcast'].values[i]))\n",
    "            fftfore = fftshift(fft2(vz[var][reg]['Forecast'].values[i]))\n",
    "\n",
    "            fftfore[np.isnan(fftfore)] = 0\n",
    "\n",
    "            # Plot the Fourier spectra\n",
    "            ffthind_norm = normalize((np.log(np.abs(ffthind))))\n",
    "            fftfore_norm = normalize((np.log(np.abs(fftfore))))\n",
    "\n",
    "            im0 = ax1[j,i].imshow(dmag_hind, vmin = dmag_hind.mean() - dmag_hind.std(), vmax = dmag_hind.mean() + dmag_hind.std(), cmap='hot')\n",
    "            ax1[j,i].set_title(f\"{str(vz[var][reg]['Hindcast'][i].time.values)[0:10]}, f{ind_forecast[i]}\", fontsize = 17)\n",
    "            im1 = ax1[j+1,i].imshow(dmag_fore, vmin = dmag_fore.mean() - dmag_fore.std(), vmax = dmag_fore.mean() + dmag_fore.std(), cmap='hot') \n",
    "            ax1[j,i].set_xticks([])\n",
    "            ax1[j,i].set_yticks([])\n",
    "            ax1[j+1,i].set_xticks([])\n",
    "            ax1[j+1,i].set_yticks([])\n",
    "\n",
    "\n",
    "            im2 = ax2[j,i].imshow(ffthind_norm, vmin = 0, vmax = 1, cmap='icefire')\n",
    "            ax2[j,i].set_title(f\"{str(vz[var][reg]['Hindcast'][i].time.values)[0:10]}, f{ind_forecast[i]}\", fontsize = 17)\n",
    "            im3 = ax2[j+1,i].imshow(fftfore_norm, vmin = 0, vmax = 1, cmap='icefire')\n",
    "            ax2[j,i].set_xticks([])\n",
    "            ax2[j,i].set_yticks([])\n",
    "            ax2[j+1,i].set_xticks([])\n",
    "            ax2[j+1,i].set_yticks([])\n",
    "            \n",
    "            if i == max_iter-1:\n",
    "\n",
    "                imratio=0.047*(dmag_hind.shape[0]/dmag_hind.shape[1])\n",
    "                cbar0 = fig.colorbar(im0, ax=ax1[j,i], fraction=imratio)\n",
    "                cbar1 = fig.colorbar(im1, ax=ax1[j+1,i], fraction=imratio)\n",
    "                cbar0.set_label('Normalized Gradient')\n",
    "                cbar1.set_label('Normalized Gradient')\n",
    "                \n",
    "                imratio=0.047*(ffthind_norm.shape[0]/ffthind_norm.shape[1])\n",
    "                cbar2 = fig.colorbar(im2, ax=ax2[j,i], fraction=imratio)\n",
    "                cbar3 = fig.colorbar(im3, ax=ax2[j+1,i], fraction=imratio)\n",
    "                cbar2.set_label('Normalized Gradient')\n",
    "                cbar3.set_label('Normalized Gradient')\n",
    "                \n",
    "\n",
    "    # Some axis labels\n",
    "    ax1[j+1,0].set_ylabel(f\"Forecast {vz[var][reg]['Filetype']} {vz[var][reg]['Polarization']}\", fontsize = 15)\n",
    "    ax1[j,0].set_ylabel(f\"Hindcast {vz[var][reg]['Filetype']} {vz[var][reg]['Polarization']}\", fontsize = 15)\n",
    "    ax2[j,0].set_ylabel(f\"Hindcast {vz[var][reg]['Filetype']} {vz[var][reg]['Polarization']}\", fontsize = 15)\n",
    "    ax2[j+1,0].set_ylabel(f\"Forecast {vz[var][reg]['Filetype']} {vz[var][reg]['Polarization']}\", fontsize = 15)\n",
    "\n",
    "    # Remove the second column of ax if it is empty\n",
    "    if num_columns <= 1:\n",
    "        for i in range(len(ax1)):\n",
    "            fig1.delaxes(ax1[i][1])\n",
    "            fig2.delaxes(ax2[i][1])\n",
    "\n",
    "    # rearange the axes for no overlap\n",
    "    fig1.tight_layout()\n",
    "    fig2.tight_layout()\n",
    "\n",
    "\n",
    "    # Create the first title for the first two rows\n",
    "    title1 = fig1.text(0, 0.75, 'Discharge', va='center', ha='center', rotation='vertical', color='red', fontsize = 20)\n",
    "    title21 = fig2.text(0, 0.75, 'Discharge', va='center', ha='center', rotation='vertical', color='red', fontsize = 20)\n",
    "\n",
    "    # Create the second title for the last two rows\n",
    "    title12 = fig1.text(0, 0.25, 'Precipitations', va='center', ha='center', rotation='vertical', color='red', fontsize = 20)\n",
    "    title22 = fig2.text(0, 0.25, 'Precipitations', va='center', ha='center', rotation='vertical', color='red', fontsize = 20)\n",
    "\n",
    "    # Add the red line in the middle\n",
    "    line1 = plt.Line2D([0, 1], [0.485, 0.485], transform=fig1.transFigure, color='red', linewidth=2)\n",
    "    line2 = plt.Line2D([0, 1], [0.485, 0.485], transform=fig2.transFigure, color='red', linewidth=2)\n",
    "    fig1.add_artist(line1)\n",
    "    fig2.add_artist(line2)\n",
    "    # Save the figures separately\n",
    "    fig1.savefig(pathfig/\"Gradients_{times[0].strftime('%Y-%m-%d')}_{times[start_ind].strftime('%Y-%m-%d')}.png\")\n",
    "    fig2.savefig(pathfig/\"FFTs_{times[0].strftime('%Y-%m-%d')}_{times[start_ind].strftime('%Y-%m-%d')}.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8e65b18-72e6-41e0-be72-a602dc6f5b45",
   "metadata": {},
   "source": [
    "**Histogram of the REOFs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602d8820-80d3-4b62-b9dc-617d53613220",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the histogram of values\n",
    "fig, ax = plt.subplots(figsize=(fig_width, 15), nrows = 2, ncols = 2)\n",
    "\n",
    "for var, j in zip(['Q', 'ERA'], range(2)):\n",
    "    for reg, i in zip(['Polynomial','Neural'], range(2)):\n",
    "            ax[j, i].hist(np.mean(vz[var][reg]['Reof_Diff_Spatial'].values, axis = 0), bins=10)  # Adjust the number of bins as needed\n",
    "            ax[j, i].set_xlabel('Score')\n",
    "            ax[j, i].set_ylabel('Frequency')\n",
    "            ax[j, i].set_title(f\"{var} {reg}: Diff Normalized Forecast modes - Data modes\")\n",
    "            ax[j, i].legend([f\"Mode {i+1}\" for i in range(vz[var][reg]['Reof_Diff_Spatial'].shape[2])])\n",
    "    \n",
    "\n",
    "plt.savefig(pathfig/f\"Histogram_difference_Discharge_{times[start_ind:stop_ind][ind_hindcast][0].strftime('%Y-%m-%d')}_{times[start_ind:stop_ind][ind_hindcast][-1].strftime('%Y-%m-%d')}.png\", dpi = 400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbccf85-63e1-4a2d-a59f-4019863df3c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hydrosar [conda env:.local-hydrosar]",
   "language": "python",
   "name": "conda-env-.local-hydrosar-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
